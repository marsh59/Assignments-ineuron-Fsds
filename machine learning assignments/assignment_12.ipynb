{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c57a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d416e2ac",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe854b",
   "metadata": {},
   "source": [
    "1.What is prior probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf3b63",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2022d94",
   "metadata": {},
   "source": [
    " Prior probability shows the likelihood of an outcome in a given dataset. For example, in the mortgage case, P(Y) is the default rate on a home mortgage, which is 2%. P(Y|X) is called the conditional probability, which provides the probability of an outcome given the evidence, that is, when the value of X is known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12331b5",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e9acb4",
   "metadata": {},
   "source": [
    "2.What is posterior probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc26f2",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e932dfb",
   "metadata": {},
   "source": [
    "Posterior probability is a revised probability that takes into account new available information. For example, let there be two urns, urn A having 5 black balls and 10 red balls and urn B having 10 black balls and 5 red balls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026ceba",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de765296",
   "metadata": {},
   "source": [
    "3.What is likelihood probability? Give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06ddaf",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd580971",
   "metadata": {},
   "source": [
    "Likelihood Function in Machine Learning and Data Science is the joint probability distribution(jpd) of the dataset given as a function of the parameter. Think of it as the probability of obtaining the observed data given the parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba323310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc037bfb",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd89d60",
   "metadata": {},
   "source": [
    "4.What is Naïve Bayes classifier? Why is it named so?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee5547b",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407eadf",
   "metadata": {},
   "source": [
    "Naive Bayes is a simple and powerful algorithm for predictive modeling. Naive Bayes is called naive because it assumes that each input variable is independent. This is a strong assumption and unrealistic for real data; however, the technique is very effective on a large range of complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4931c0f",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb89006",
   "metadata": {},
   "source": [
    "5.What is optimal Bayes classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657daea3",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcee590",
   "metadata": {},
   "source": [
    " The Bayes Optimal Classifier is a probabilistic model that makes the most probable prediction for a new example. Bayes Optimal Classifier is a probabilistic model that finds the most probable prediction using the training data and space of hypotheses to make a prediction for a new data instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b58726b",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a66012",
   "metadata": {},
   "source": [
    "6.Write any two features of Bayesian learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f5a36",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78539d",
   "metadata": {},
   "source": [
    "A probability distribution over observed data for each possible hypothesis. New instances can be classified by combining the predictions of multiple hypotheses, weighted by their probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af1f11",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0045e0",
   "metadata": {},
   "source": [
    "7.Define the concept of consistent learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3fbca",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0db2c",
   "metadata": {},
   "source": [
    "Consistent Learners: A learner L using a hypothesis H and training data D is said to be a consistent learner if it always outputs a hypothesis with zero error on D whenever H contains such a hypothesis. • By definition, a consistent learner must produce a hypothesis in the version space for H given D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed3893d",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55073c1a",
   "metadata": {},
   "source": [
    "8.Write any two strengths of Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0322055",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6a7f9",
   "metadata": {},
   "source": [
    "This algorithm works quickly and can save a lot of time. Naive Bayes is suitable for solving multi-class prediction problems. If its assumption of the independence of features holds true, it can perform better than other models and requires much less training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fbd0a",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac103c2c",
   "metadata": {},
   "source": [
    "9.Write any two weaknesses of Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb1d2d",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c2beb",
   "metadata": {},
   "source": [
    "The greatest weakness of the naïve Bayes classifier is that it relies on an often-faulty assumption of equally important and independent features which results in biased posterior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eed827",
   "metadata": {},
   "source": [
    "# q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab7fd42",
   "metadata": {},
   "source": [
    "10.Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "1. Text classification\n",
    "\n",
    "2. Spam filtering\n",
    "\n",
    "3. Market sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4231e95",
   "metadata": {},
   "source": [
    "# ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff455ae5",
   "metadata": {},
   "source": [
    "* Text classification: \n",
    "\n",
    "The Naive Bayes classifier is a simple classifier that classifies based on probabilities of events. It is the applied commonly to text classification. With the training set, we can train a Naive Bayes classifier which we can use to automaticall categorize a new sentence.\n",
    "\n",
    "* Spam filtering:\n",
    "\n",
    "Naive Bayes classifiers work by correlating the use of tokens (typically words, or sometimes other things), with spam and non-spam e-mails and then using Bayes' theorem to calculate a probability that an email is or is not spam. It is one of the oldest ways of doing spam filtering, with roots in the 1990s.\n",
    "\n",
    "* Market sentiment analysis:\n",
    "\n",
    "Market Sentiment analysis is a field dedicated to extracting subjective emotions and feelings from text. One common use of sentiment analysis is to figure out if a text expresses negative or positive feelings. Naive Bayes is a popular algorithm for classifying text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f971e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
